{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### explore data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['title', 'text', 'url'])\n",
      "Pandemic\n",
      "A pandemic (from Greek πᾶ\n",
      "https://en.wikipedia.org/wiki/Pandemic\n"
     ]
    }
   ],
   "source": [
    "with open(\"data/data.json\", mode = \"rb\") as file:\n",
    "    file_obj = json.load(file)\n",
    "    \n",
    "    for index, file in enumerate(file_obj):\n",
    "        print(file.keys())\n",
    "        print(file[\"title\"])\n",
    "        print(file[\"text\"][0:25])\n",
    "        print(file[\"url\"])\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Python function that takes in a text string,\n",
    "# performs all operations described in the previous step, \n",
    "# and outputs a list of tokens (lemmas).\n",
    "# Lowercases the text string.\n",
    "# Creates a spaCy document with the text lemmas and their attributes \n",
    "# using a spaCy model of your choice.\n",
    "# Removes stop words, punctuation, and other unclassified lemmas.\n",
    "# Returns a list of tokens (lemmas) found in the text.\n",
    "\n",
    "## Doc -> Span(Slice of items) -> Token (a specific item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(content_doc):\n",
    "    \"\"\"\n",
    "    This function perform the following operations:\n",
    "    - Lowercases the text string.\n",
    "    - Creates a spaCy document with the text lemmas and \n",
    "        their attributes using a spaCy model of your choice.\n",
    "    - Removes stop words, punctuation, and other unclassified lemmas.\n",
    "    - Returns a list of tokens (lemmas) found in the text.    \n",
    "    \n",
    "    :param doc_content: Document content\n",
    "    :type content_doc: str\n",
    "    :return: List of tokens (lemmas)\n",
    "    \n",
    "    \"\"\"\n",
    "    content_doc = content_doc.lower()\n",
    "    \n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "    content_doc = content_doc.lower()\n",
    "    \n",
    "    # doc contains the text lemmas and their attributes\n",
    "    # https://spacy.io/api/doc\n",
    "    doc = nlp(content_doc)\n",
    "       \n",
    "     # remove stop words\n",
    "    all_stopwords = nlp.Defaults.stop_words\n",
    "    tokens_without_sw = [word for word in doc if word not  in all_stopwords]\n",
    "    \n",
    "    # remove punctuation and stop words\n",
    "    tokens_without_pct = [token for token in tokens_without_sw \n",
    "                          if not token.is_punct and not token.is_stop]\n",
    "    \n",
    "    # Get Lemmas\n",
    "    token_lemmas = [\n",
    "                        token.lemma_ for token\n",
    "                            in tokens_without_pct\n",
    "                               if len(token.dep_.strip())>0\n",
    "                                and token.lemma_ != \"\\n\"\n",
    "                                and token.dep_\n",
    "                        ]\n",
    "    \n",
    "    return token_lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pandemic\n",
      "Epidemiology of HIV/AIDS\n",
      "Antonine Plague\n",
      "Basic reproduction number\n",
      "Bills of mortality\n",
      "Cholera\n",
      "COVID-19 pandemic\n",
      "Crimson Contagion\n",
      "Disease X\n",
      "Event 201\n",
      "HIV/AIDS\n",
      "HIV/AIDS in Yunnan\n",
      "Pandemic prevention\n",
      "Pandemic Severity Assessment Framework\n",
      "Pandemic severity index\n",
      "Plague of Cyprian\n",
      "PREDICT (USAID)\n",
      "1929–1930 psittacosis pandemic\n",
      "Science diplomacy and pandemics\n",
      "Spanish flu\n",
      "Superspreader\n",
      "Swine influenza\n",
      "Targeted immunization strategies\n",
      "Unified Victim Identification System\n",
      "Viral load\n",
      "Virus\n"
     ]
    }
   ],
   "source": [
    "with open(\"data/data.json\", mode = \"rb\") as file:\n",
    "    file_obj = json.load(file)\n",
    "    for index, file in enumerate(file_obj):\n",
    "        print(file[\"title\"])\n",
    "        file[\"tokenized_text\"] = preprocess(file[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/result.json', 'w') as output:\n",
    "    json.dump(file_obj, output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test spacy\n",
    "https://spacy.io/usage/spacy-101#annotations-token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
    "doc = nlp(\"It's over Anakin! I have the high ground\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.doc.Doc"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.span.Span"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(doc[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.token.Token"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(doc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[2].is_punct "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
